import os
import requests
from openai import OpenAI
import json
from dotenv import load_dotenv
from pprint import pprint

load_dotenv()

OPENAI_API_KEY = os.getenv('OPEN_AI_API_KEY')
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_SECRET_ID = os.getenv("NAVER_SECRET_ID")

client = OpenAI(api_key=OPENAI_API_KEY)
model = 'gpt-4o-mini'

BASE_URL = "https://openapi.naver.com/v1/search/news.json"

# 네이버 뉴스를 가져오는 함수
def get_naver_news(query: str, display: int = 10, start: int = 1, sort: str = "date"):

    if not NAVER_CLIENT_ID or not NAVER_SECRET_ID:
        raise RuntimeError("ENV에 NAVER_CLIENT_ID / NAVER_SECRET_ID가 없습니다.")

    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_SECRET_ID,
    }

    params = {
        "query": query,
        "display": display,
        "start": start,
        "sort": sort,
    }

    r = requests.get(BASE_URL, headers=headers, params=params, timeout=15)
    r.raise_for_status()
    return r.json()

# data = get_naver_news("인공지능", display=5, sort="date")
# pprint(data)

tools = [
    {
        "type": "function",
        "name": "get_naver_news",
        "description": "최근 AI 개발자 관련 뉴스들만 가져옵니다.",
        "parameters": {
            "type": "object",
            "properties": {
                # "query" : {
                #     "type": "string",
                #     "description": "삼성전자 주가 관련 내용만 가져옵니다."
                # }
            }
        }
    }
]

def run_conversation(user_prompt):
    input_list = [{"role": "user", "content": user_prompt}]

    # 1. LLM에게 1차 요청을 한다.
    response = client.responses.create(
        model=model,
        input=input_list,
        tools=tools,
    )
    input_list += response.output
    
    # 2. LLM의 응답에서 "함수 실행"에 대한 응답이 있다면 이를 실행한다.
    for item in response.output:
        if item.type == "function_call":
            if item.name == 'get_naver_news':

                result = get_naver_news("인공지능", display=5, sort="date", **json.loads(item.arguments))
                # 3. 함수 실행 결과를 input에 담는다.
                input_list.append({
                    "type": "function_call_output",
                    "call_id": item.call_id,
                    "output": json.dumps({
                    "result": result
                    })
                })
    # 4. 다시 한번 LLM에게 요청한다.
    response = client.responses.create(
        model=model,
        instructions="Respond only with a movies generated by a tool.",
        tools=tools,
        input=input_list,
    )

    return response.output_text
 
print(run_conversation("최근 개발자 전망이 어때?"))

